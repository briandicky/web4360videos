<!DOCTYPE HTML>
<!-- Website template by freewebsitetemplates.com -->
<html>
<head>
	<meta charset="UTF-8">
	<title>Networking and Multimedia Systems Lab</title>
	<link rel="stylesheet" href="css/style.css" type="text/css">
</head>
<body>
	<div id="header">
		<div>
			<div class="logo" align="center">
				<a href="index.html">NMSL@NTHU</a>
			</div>
			<ul id="navigation">
				<li>
					<a href="index.html">Home</a>
				</li>
                <li class="active">
                    <a href="research.html">Research</a>
                </li>
				<li>
					<a href="document.html">Document</a>
				</li>
				<li>
					<a href="download.html">Download</a>
				</li>
				<li>
					<a href="faq.html">FAQ</a>
				</li>
				<li>
					<a href="contact.html">Contact</a>
				</li>
			</ul>
		</div>
	</div>
	<div id="contents">
        <h1>
            <b>Research Activities</b>
        </h1>

        <div class="post">
            <div class="date">
                <p>
                <span>07</span>
                2017
                </p>
            </div>
            <h3>Performance Measurements of 360° Video Streaming to HMDs over 4G Cellular Networks<span class="author">by Wec-Chih</span></h3>
            <p style="margin: 0px;">
            Streaming 360° videos further increases the Internet traffic amount.
            In particular, streaming videos coded in 4K or higher resolutions leads to insufficient bandwidth and overloaded decoder. As shown in
            Fig. 4, when watching 360° videos, a viewer wearing an HMD rotates his/her head to actively change the viewing orientation. 
            Viewing orientation can be described by yaw, pitch, and roll, which correspond to rotating along x, y, and z axes. 
            A viewer with HMD only gets to see a small part of the whole video. 
            Most of the 360° videos won’t be viewed by a viewer, and thus streaming the whole 360° videos may be unnecessary.
            </p>

            <div style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="images/apnoms_view_fov.png">
                    <figcaption>Figure 4: A viewer watches a part of whole 360° video with an HMD.</figcaption>
                </figure>
            </div>

            <p style="margin: 0px;">
            To solve this problem, Fig. 5 shows that a video is split into tiles of sub-videos, which are then encoded by <a href="http://ieeexplore.ieee.org/document/6375943/">HEVC (High Efficiency Video Coding)</a> codec into video bitstreams. 
            Then, we stream them using <a href="http://dl.acm.org/citation.cfm?doid=1943552.1943572">MPEG Dynamic Adaptive Streaming over HTTP (DASH)</a>, an adaptive streaming technology for delivering
            videos over the Internet. 
            For DASH streaming systems, each tile is encoded into multiple versions at different bitrates. 
            This provides the ability for a client to switch among different bitrates or quality levels. 
            Having multiple tiles allows each client to only request and decode those tiles that will be watched, in order to conserve resources. 
            However, splitting a video into tiles may reduce the coding efficiency, compared to a single non-tiled video.
            </p>

            <div style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="images/apnoms_preprocessing.jpg">
                    <figcaption>Figure 5: Overview of the pre-processing procedure of our 360° video streaming platform.</figcaption>
                </figure>
            </div>

            <p>
            Therefor, we design several experiments for quantifying the performance of 360° video streaming over a real cellular network on our campus. 
            In particular, we investigate diverse impacts of tile streaming over 4G networks, such as the coding efficiency, the potential of saving bandwidth, and the number of the supportable clients. 
            Our experiments make several interesting findings, for example, (i) only streaming the tiles viewed by the viewer achieves bitrate reduction by up to 80%, and (ii) the coding efficiency of 3x3 tiled videos may be higher than non-tiled videos at higher bitrates.
            &nbsp;<a href="">View details »</a>
            </p>
        </div>

        <hr></hr>
        <br></br>

        <div class="post">
            <div class="date">
                <p>
                <span>06</span>
                2017
                </p>
            </div>
            <h3>Fixation Prediction for 360° Video Streaming<span class="author">by Wec-Chih</span></h3>
            <p style="margin: 0px;">
            Leveraging commodity HMDs for 360° video streaming is, however, very challenging for two reasons. 
            First, 360° videos contain much more information than conventional videos, and thus are much larger in resolutions and file sizes.
            With HMDs, each viewer only gets to see a small part of the whole video. 
            Therefore, sending the whole 360° video in full resolution may lead to waste of resources, such as network bandwidth, processing power, and storage space.
            Another way to stream 360° videos to HMDs is to only stream the current FoV of the viewer. 
            We emphasize current, because the FoV changes as the viewer’s head and eyes move, which leads to the following main challenge: which FoV should we transfer to meet the viewer’s needs in the next moment.
            </p>

            <div style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="images/fixa_archi.jpg">
                    <figcaption>Figure 2: Overview of the proposed 360° video streaming server. A tile streaming example is shown.</figcaption>
                </figure>
                <figure>
                    <img src="images/fixa_sphere_coord2.jpg">
                    <figcaption>Figure 3: The FoV model.</figcaption>
                </figure>
            </div>

            <p>
                Fig. 2 presents our proposed architecture of a 360° streaming server, in which we focus on the software components related to fixation prediction. 
                We have identified two types of content-related features: <a href="https://arxiv.org/abs/1411.5878">image saliency map</a>, <a href="http://www.sciencedirect.com/science/article/pii/S0923596516301667">motion map</a>, and sensor-related features, such as orientations and angular speed, from HMDs.
                The video frames are sent to the image saliency network and motion feature detector for generating the image saliency map and the motion map, respectively. 
                Generating these two maps is potentially resource demanding, and we assume that they are created offline for pre-recorded videos. 
                Fig. 3 presents the FoV model of HMDs. The viewer stands at the center of the sphere. Let α and β be the yaw and pitch, which are reported from the sensors equipped by HMDs.
                The HMD sensor data are transmitted to the orientation extractor to derive the viewer orientations. 
                The feature buffer maintains a sliding window that stores the latest image saliency maps, motion maps, and viewer orientations as the inputs of fixation prediction network. 
                The video fixation prediction network predicts the future viewing probability of each tile. The tile rate selector optimally selects the rates of the encoded video tiles.
                &nbsp;<a href="http://dl.acm.org/citation.cfm?id=3083180">View details »</a>
            </p>
        </div>

        <hr></hr>
        <br></br>

		<div class="post">
			<div class="date">
				<p>
					<span>06</span>
					2017
				</p>
			</div>
            <h3>360° Video Viewing Dataset in Head-Mounted Virtual Reality<span class="author">by Wec-Chih</span></h3>
            <p style="margin: 0px;">
                Using conventional displays to watch 360° videos is often less intuitive, while recently released HMDs, such as Oculus Rift, HTC Vive, Samsung Gear VR, offer wider Field-of-Views (FoVs) and thus more immersive experience.
                <!--While service providers like YouTube and Facebook, have put some 360° videos online, streaming these videos to HMDs is extremely challenging.-->
                <!--One of the challenges is that 360° videos are in very high resolution, such as 4K, 8K, and higher.-->
                <!--When watching a 360° video, a viewer wearing an HMD rotates his/her head to change the viewing orientation, which can be described by the angles along the x, y, and z axes.-->
                <!--These three angles are called yaw, pitch, and roll. Based on the orientation, the HMD displays the current FoV, which is a fixed-size region, say 100°x100° circle. -->
            Since a viewer never sees a whole 360° video, streaming the 360° video in its full resolution wastes resources, including bandwidth, storage, and computation.
            Therefore, each 360° video is often split into grids of sub-images, called tiles. 
            With tiles, an optimized 360° video streaming system to HMDs would strive to stream only those tiles that fall in the viewer’s FoV. 
            
            <!--By doing so, the system satisfies the viewer’s needs and consumes less resources than streaming the whole video at its full resolution.-->
            However, getting to know each viewer’s FoVs at any moment of every 360° video is not an easy task. 
            <!--The complex interplay among too many factors increases the difficulty.-->
            <!--More specifically, both content (360° videos) and sensors (HMDs worn by viewers) affect the viewers’ FoVs in the future moments.-->
            <!--Hence, to better address the challenge, a large set of the content and sensor data from viewers watching 360° videos with HMDs is crucial.-->
            To better address the challenge, a large set of the content and sensor data from viewers watching 360° videos with HMDs is crucial.

            <div style="display: flex; justify-content: space-around; margin-top: 0px;">
                <video width="300" height="225" controls>
                    <source src="videos/480p_mega_coaster.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>

                <video width="300" height="225" controls>
                    <source src="videos/480p_coaster_saliency_10s.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>

                <video width="300" height="225" controls>
                    <source src="videos/480p_coaster_motion_10s.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>

            <br></br>

            To overcome such limitation, and promote reproducible research, we build up our own 360° video testbed for collecting traces from real viewers watching 360° videos using HMDs. 
            <!--We then use the testbed to collect content and sensor dataset.-->
            <a href="download.html" >The resulting dataset</a> can be used to, for example, predict which parts of 360° videos attract viewers to watch the most. The dataset, however, can also be leveraged in various novel applications in a much broader scope.
            <!--For example, using our dataset, content provider could get to compute the most common FoVs among viewers, and derive the crowd-driven camera movements, which may be used to guide viewers through 360° videos via innovative user interfaces.-->
            <!--Deeper investigations could even identify the essential elements for gaining viewers’ attentions in 360° videos streamed to HMDs.-->
            &nbsp;<a href="http://dl.acm.org/citation.cfm?id=3083219">View details »</a>
            </p>

		</div>
	</div>

	<div id="footer" align="center">
		<p style="margin-bottom: 0px">
			© 2017 NMSL@NTHU. All Rights Reserved.
		</p>
	</div>
</body>
</html>
